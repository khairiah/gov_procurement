{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "b6a986b9-4f3c-45f6-94d5-e77adbc6a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re # for regex\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67e130-0a68-41d7-b023-0f28048d68e2",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120122f8-ff50-4057-9d07-d78d2fcaec92",
   "metadata": {},
   "source": [
    "Fetch all rows from a data.gov.sg dataset via the v2 API.\n",
    "\n",
    "Args:\n",
    "- datasetid (str): Dataset ID from data.gov.sg (e.g. 'd_acde1106003906a75c3fa052592f2fcb')\n",
    "- api_key (str): Your developer API key\n",
    "- limit (int): Max rows per request (default=10000, API limit)\n",
    "    \n",
    "Returns:\n",
    "- pd.DataFrame: DataFrame containing all rows\n",
    "\n",
    "Note: Since this dataset has ~18000 rows, using limit=10000 we will let the pagination loop fetch in 2 calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "37b0be39-506f-4522-ac8d-7e1f31b86c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetid = \"d_acde1106003906a75c3fa052592f2fcb\"\n",
    "api_key = \"v2:a8aef9004f691fb36ad4bc60c8782306e05322cef5470508fbf3cdc0141fb5ee:jl-zKL_msEsPmgra7wNpw_2CKo9w3d_s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "96127b60-0554-4467-9328-2b804d697f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 10000 rows (offset=0)\n",
      "Fetched 8021 rows (offset=10000)\n",
      "Total rows fetched: 18021\n",
      "Columns: ['vault_id', 'tender_no', 'tender_description', 'agency', 'award_date', 'tender_detail_status', 'supplier_name', 'awarded_amt']\n",
      "  vault_id          tender_no  \\\n",
      "0        1  ACR000ETT20300002   \n",
      "1        2  ACR000ETT20300002   \n",
      "2        3  ACR000ETT20300003   \n",
      "3        4  ACR000ETT20300004   \n",
      "4        5  ACR000ETT21000001   \n",
      "\n",
      "                                  tender_description  \\\n",
      "0  INVITATION TO TENDER FOR THE PROVISION OF SERV...   \n",
      "1  INVITATION TO TENDER FOR THE PROVISION OF SERV...   \n",
      "2  PROVISION OF AN IT SECURITY CONTROLS AND OPERA...   \n",
      "3  CONCEPTUALIZATION, DESIGN, BUILD, SET-UP OF NE...   \n",
      "4  DESIGN, DEVELOPMENT, CUSTOMIZATION, DELIVERY, ...   \n",
      "\n",
      "                                          agency  award_date  \\\n",
      "0  Accounting And Corporate Regulatory Authority  10/11/2020   \n",
      "1  Accounting And Corporate Regulatory Authority  10/11/2020   \n",
      "2  Accounting And Corporate Regulatory Authority   9/12/2020   \n",
      "3  Accounting And Corporate Regulatory Authority    9/3/2021   \n",
      "4  Accounting And Corporate Regulatory Authority    6/9/2021   \n",
      "\n",
      "   tender_detail_status                                      supplier_name  \\\n",
      "0      Awarded by Items  DELOITTE & TOUCHE ENTERPRISE RISK SERVICES PTE...   \n",
      "1      Awarded by Items                            KPMG SERVICES PTE. LTD.   \n",
      "2  Awarded to Suppliers                   ERNST & YOUNG ADVISORY PTE. LTD.   \n",
      "3  Awarded to Suppliers                  D' PERCEPTION SINGAPORE PTE. LTD.   \n",
      "4  Awarded to Suppliers                              ALPHA ZETTA PTE. LTD.   \n",
      "\n",
      "  awarded_amt  \n",
      "0      285000  \n",
      "1       90000  \n",
      "2      182400  \n",
      "3   3071056.4  \n",
      "4     2321600  \n"
     ]
    }
   ],
   "source": [
    "def fetch_dataset(datasetid, api_key, limit=10000):\n",
    "    url = f\"https://api-production.data.gov.sg/v2/public/api/datasets/{datasetid}/list-rows\"\n",
    "    headers = {\"x-api-key\": api_key}\n",
    "    \n",
    "    all_rows = []\n",
    "    offset = 0\n",
    "    \n",
    "    while True:\n",
    "        params = {\"limit\": limit, \"offset\": offset}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "        \n",
    "        json_data = response.json()\n",
    "        rows = json_data[\"data\"][\"rows\"]\n",
    "        \n",
    "        if not rows:  # stop if no more data\n",
    "            break\n",
    "        \n",
    "        # Extract inner row dicts\n",
    "        records = [r.get(\"row\", r) for r in rows]\n",
    "        all_rows.extend(records)\n",
    "        \n",
    "        print(f\"Fetched {len(records)} rows (offset={offset})\")\n",
    "        \n",
    "        # Prepare for next batch\n",
    "        offset += limit\n",
    "    \n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "\n",
    "df = fetch_dataset(datasetid, api_key)\n",
    "print(\"Total rows fetched:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "4f1bbdd6-363d-48f4-9b1d-5102ff94ad1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18021, 8)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #how big the dataset is - 18021 rows, 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "fb7f4d39-81ac-43fc-bf7d-92d84cb23f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18021 entries, 0 to 18020\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   vault_id              18021 non-null  object\n",
      " 1   tender_no             18021 non-null  object\n",
      " 2   tender_description    18021 non-null  object\n",
      " 3   agency                18021 non-null  object\n",
      " 4   award_date            18021 non-null  object\n",
      " 5   tender_detail_status  18021 non-null  object\n",
      " 6   supplier_name         18021 non-null  object\n",
      " 7   awarded_amt           18021 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # get summary of DataFrame, including data types. alternative way: using `df.dtypes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "5446995f-95c5-4d39-9f77-aae98e4682b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vault_id</th>\n",
       "      <th>tender_no</th>\n",
       "      <th>tender_description</th>\n",
       "      <th>agency</th>\n",
       "      <th>award_date</th>\n",
       "      <th>tender_detail_status</th>\n",
       "      <th>supplier_name</th>\n",
       "      <th>awarded_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ACR000ETT20300002</td>\n",
       "      <td>INVITATION TO TENDER FOR THE PROVISION OF SERV...</td>\n",
       "      <td>Accounting And Corporate Regulatory Authority</td>\n",
       "      <td>10/11/2020</td>\n",
       "      <td>Awarded by Items</td>\n",
       "      <td>DELOITTE &amp; TOUCHE ENTERPRISE RISK SERVICES PTE...</td>\n",
       "      <td>285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACR000ETT20300002</td>\n",
       "      <td>INVITATION TO TENDER FOR THE PROVISION OF SERV...</td>\n",
       "      <td>Accounting And Corporate Regulatory Authority</td>\n",
       "      <td>10/11/2020</td>\n",
       "      <td>Awarded by Items</td>\n",
       "      <td>KPMG SERVICES PTE. LTD.</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ACR000ETT20300003</td>\n",
       "      <td>PROVISION OF AN IT SECURITY CONTROLS AND OPERA...</td>\n",
       "      <td>Accounting And Corporate Regulatory Authority</td>\n",
       "      <td>9/12/2020</td>\n",
       "      <td>Awarded to Suppliers</td>\n",
       "      <td>ERNST &amp; YOUNG ADVISORY PTE. LTD.</td>\n",
       "      <td>182400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vault_id          tender_no  \\\n",
       "0        1  ACR000ETT20300002   \n",
       "1        2  ACR000ETT20300002   \n",
       "2        3  ACR000ETT20300003   \n",
       "\n",
       "                                  tender_description  \\\n",
       "0  INVITATION TO TENDER FOR THE PROVISION OF SERV...   \n",
       "1  INVITATION TO TENDER FOR THE PROVISION OF SERV...   \n",
       "2  PROVISION OF AN IT SECURITY CONTROLS AND OPERA...   \n",
       "\n",
       "                                          agency  award_date  \\\n",
       "0  Accounting And Corporate Regulatory Authority  10/11/2020   \n",
       "1  Accounting And Corporate Regulatory Authority  10/11/2020   \n",
       "2  Accounting And Corporate Regulatory Authority   9/12/2020   \n",
       "\n",
       "   tender_detail_status                                      supplier_name  \\\n",
       "0      Awarded by Items  DELOITTE & TOUCHE ENTERPRISE RISK SERVICES PTE...   \n",
       "1      Awarded by Items                            KPMG SERVICES PTE. LTD.   \n",
       "2  Awarded to Suppliers                   ERNST & YOUNG ADVISORY PTE. LTD.   \n",
       "\n",
       "  awarded_amt  \n",
       "0      285000  \n",
       "1       90000  \n",
       "2      182400  "
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3) #first 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f35d5-532f-4ac2-94b8-f76242606a03",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "86f5dc00-df20-4e2d-94a6-6536ee441a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for empty values before cleaning:\n",
      " vault_id                0\n",
      "tender_no               0\n",
      "tender_description      0\n",
      "agency                  0\n",
      "award_date              0\n",
      "tender_detail_status    0\n",
      "supplier_name           0\n",
      "awarded_amt             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if the file already has missing values before any transformations\n",
    "print(\"Checking for empty values before cleaning:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84ba1a-8c27-40ae-b50d-0fca8d348660",
   "metadata": {},
   "source": [
    "## 1) `tender_no` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c2507-7190-446b-9567-7c3a91b217f0",
   "metadata": {},
   "source": [
    "- Alphanumeric ID\n",
    "- `tender_no` is NOT UNIQUE. Same tenders shows up on multiple rows as a tender may be split across **multiple** suppliers. \n",
    "- A tender amy also have multiple line items (e.g. laptops, printers, services). \n",
    "- A tender may even have some items awarded or not. There's one tender with `FINVITETT20300009` tendor ID  which appears 131 times in the dataset.\n",
    "- Transformation(s)\n",
    "    - Strip whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "fe01482b-ceb8-4d32-8fda-0e403a922d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tender_no_clean'] = df['tender_no'].str.strip() #strip whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "40411b7c-e949-4668-9070-1b2e849b0f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11915\n"
     ]
    }
   ],
   "source": [
    "# tender IDs are not unique. Use .nunique() to tell us how many UNIQUE tender IDs there are over the past years. Not sure why 9 only? IMPORTANT\n",
    "print(df['tender_no_clean'].nunique())   # ✅ 11915 as of 18 Aug 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34977cf6-c8fd-4810-bca9-416a25d4ba98",
   "metadata": {},
   "source": [
    "## 2) `tender_description`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f839ff-a130-41c2-9bea-10b6cc7c46e3",
   "metadata": {},
   "source": [
    "- Long-text with varied casing (e.g. some descriptions are in ALL CAPS while some are Mixed Case)\n",
    "- Transformation(s)\n",
    "    - Strip whitespace\n",
    "    - Convert to lowercase (for future enhancements - text classification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "25ad1430-5cb9-4ba0-b3eb-c309e432d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tender_description:\n",
      " 15703    design, build and management for untame onsite...\n",
      "13596    north east community development council (necd...\n",
      "7637     itt for provision of maintenance services for ...\n",
      "669      invitation to tender for the provision of msf ...\n",
      "Name: tender_description_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['tender_description_clean'] = df['tender_description'].str.strip().str.lower()\n",
    "print(\"Sample tender_description:\\n\", df['tender_description_clean'].sample(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28374f8e-03c5-411c-ad96-4d95d39e0b6d",
   "metadata": {},
   "source": [
    "## 3) `agency`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc0a1b-1ba9-49bb-9908-5acad3fce02b",
   "metadata": {},
   "source": [
    "- Values are mixed casing but consistent. E.g. `Ministry of Education`, `Attorney-General's Chambers`.\n",
    "    - Did not convert to uppercase as you'll lose readability. \n",
    "- For easier querying in DB by analysts, map it to a controlled vocabulary of \"shortform\" names for respective agencies. E.g. `Ministry of Education` -> `MOE`\n",
    "- **Transformation(s)**\n",
    "    - Trim whitespace, keep title case\n",
    "    - **Challenges:**\n",
    "        - Singapore has dozens of staturatory boards, ministries, councils, etc.\n",
    "            - Core Ministries (MOE, MOH, MINDEF, etc)\n",
    "            - Statutory Boards (ACRA, BCA, LTD, HDB, etc)\n",
    "        - Formatting differences: `Ministry of Education - Schools` vs `Ministry of Education`, `Supreme Court - State Courts` vs `Supreme Court of Singapore`\n",
    "        - Some procuring entity is often listed as the sub-unit of a ministry. E.g. Instead of `Ministry of Education`, tender listed as `Temasek Polytechnic`. This means schools (or even polytechnics, junior colleges, statutory boards) procure directly, but they are still under MOE's umbrella. So the `agency` column is not just ministries/stat boards — it sometimes includes schools, IHLs, or specific institutions.\n",
    "        - Options\n",
    "            - **1) Leave as-is**\n",
    "                - Pros: Preserves raw truth, most accurate\n",
    "                - Cons: Have 100s of unique agencies (MOE schools, hospitals, etc) making aggregation harder for analysts down the ro\n",
    "            - **2) Group under parent agency**\n",
    "                - E.g. Map all schools/tertiary education back to \"Ministry of Education\". Map all hospitals to \"Ministry of Health\"\n",
    "                - Pros:\n",
    "                    - Cleaner analysis at ministry/stat board level\n",
    "                - Cons:\n",
    "                    - Lose granularity (can't see which specific school procured)\n",
    "            - **Decision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "a0c33966-542c-4254-bfc0-4c5837dc2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping a permanent copy of the original\n",
    "if 'agency_raw' not in df.columns:   # only create once!\n",
    "    df['agency_raw'] = df['agency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "ac0fcd54-a9a9-4b5d-9e28-9dcdbcb6e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Whitespace issues:\n",
      " Leading/trailing spaces: 32\n",
      " Double spaces inside: 358\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove any leading/trailing spaces (if any)\n",
    "leading_trailing = (df['agency_raw'] != df['agency_raw'].str.strip()).sum()\n",
    "\n",
    "# 2. Collapse double spaces (if any)\n",
    "double_spaces = df['agency_raw'].str.contains(r\"\\s{2,}\", regex=True).sum()\n",
    "\n",
    "print(\"\\nWhitespace issues:\")\n",
    "print(\" Leading/trailing spaces:\", leading_trailing)\n",
    "print(\" Double spaces inside:\", double_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "077b5812-8a85-4e3f-af80-4766eb509036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with ' - ' (with space): 1981\n",
      "Rows with '-' (no space): 1294\n"
     ]
    }
   ],
   "source": [
    "# 3. Dash inconsistencies\n",
    "with_space = df['agency_raw'].str.contains(\" - \", regex=False).sum()\n",
    "without_space = df['agency_raw'].str.contains(r\"[^ ]-[^ ]\", regex=True).sum()\n",
    "print(\"Rows with ' - ' (with space):\", with_space)\n",
    "print(\"Rows with '-' (no space):\", without_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "4b5a497c-c659-4814-a907-5450beeba28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agencies with aliases/brackets:\n",
      "   Competition and Consumer Commission of Singapore (CCCS)\n",
      "   Gambling Regulatory Authority of Singapore (GRA)\n",
      "   Government Technology Agency  (GovTech)\n",
      "   Anglo-Chinese School (Independent)\t\n",
      "   Methodist Girls' School (Secondary)\n",
      "   Raffles Girls' School (Secondary)\n",
      "   Singapore Sports Council (Sport Singapore) - SPC\n",
      "   Singapore Sports Council (Sport Singapore)\n"
     ]
    }
   ],
   "source": [
    "#4. Bracketed aliases\n",
    "aliases = df[df['agency_raw'].str.contains(r\"\\(.*\\)\", na=False)]['agency'].unique()\n",
    "print(\"\\nAgencies with aliases/brackets:\")\n",
    "for a in aliases:\n",
    "    print(\"  \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "c2ee86d8-fd45-436c-b306-bca896137cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agencies with 'Ministry Headquarter' suffix:\n",
      "   Ministry of Culture, Community and Youth - Ministry Headquarter\n",
      "   Ministry of Social and Family Development - Ministry Headquarter\n",
      "   Ministry of Transport - Ministry Headquarter\n",
      "   Ministry of Finance-Ministry Headquarter\n",
      "   Ministry of Health-Ministry Headquarter\n",
      "   Ministry of Home Affairs-Ministry Headquarter\n",
      "   Ministry of Law-Ministry Headquarter\n",
      "   Ministry of Home Affairs - Ministry Headquarter 1\n",
      "   Ministry of Manpower-Ministry Headquarter\n",
      "   Ministry of National Development-Ministry Headquarter\n",
      "   Prime Minister's Office-Ministry Headquarter\n",
      "   Ministry of Trade & Industry-Ministry Headquarter\n"
     ]
    }
   ],
   "source": [
    "# 5. Ministry Headquarter suffix \n",
    "hq = df[df['agency'].str.contains(\"Ministry Headquarter\", na=False)]['agency'].unique()\n",
    "print(\"\\nAgencies with 'Ministry Headquarter' suffix:\")\n",
    "for a in hq:\n",
    "    print(\"  \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "ace6a94b-fb51-485a-bd7b-12924510f6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique agencies before cleaning: 111\n"
     ]
    }
   ],
   "source": [
    "# 6. Overall unique values\n",
    "print(\"\\nUnique agencies before cleaning:\", df['agency'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "d45acbaa-46f8-4e33-8bfb-f2712b05927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations step by step into new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "3ce30947-4e2f-4c5d-b1b2-f50fd8a75415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Base cleaning - strip, normalize spaces, apostrophes, dash spacing, unnecessary trailing text\n",
    "df['agency_clean'] = (\n",
    "       df['agency_raw']\n",
    "      .str.strip()                                       # remove leading/trailing\n",
    "      .str.replace('\\u00A0', ' ', regex=False)        # normalize non-breaking space\n",
    "      .str.replace('\\u2011', '-', regex=False)        # NEW: normalize non-breaking hyphen\n",
    "      .str.replace(r'[\\u2010\\u2012\\u2013\\u2014\\u2015\\u2212-]', '-', regex=True)  # keep your existing normalizer\n",
    "      .str.replace(r'\\s*-\\s*', ' - ', regex=True)        # cont: this will catch all (already unified) hyphens\n",
    "      .str.replace(\"’\", \"'\", regex=False)                # curly apostrophe → straight\n",
    "      .str.replace(r'\\s*(?:-\\s*)?(?:\\((?:MDA|CCCS|GRA|SPC)\\)|(?:MDA|CCCS|GRA|SPC))\\s*$', '', regex=True)\n",
    "      .str.replace(r', Singapore$', '', regex=True)      # remove trailing \", Singapore\"\n",
    "      .str.replace(r'\\s*\\((GovTech)\\)', '', regex=True)  # remove GovTech alias\n",
    "      .str.replace(r'\\s{2,}', ' ', regex=True)           # collapse multiple spaces (do this near the end)\n",
    "      .str.strip()                                       # final cleanup# final cleanup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "77a21e9e-5f8b-42c1-8970-1dfcf0061bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_raw</th>\n",
       "      <th>agency_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16411</th>\n",
       "      <td>Singapore Sports Council (Sport Singapore) - SPC</td>\n",
       "      <td>Singapore Sports Council (Sport Singapore)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16742</th>\n",
       "      <td>Singapore Sports Council (Sport Singapore)</td>\n",
       "      <td>Singapore Sports Council (Sport Singapore)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             agency_raw  \\\n",
       "16411  Singapore Sports Council (Sport Singapore) - SPC   \n",
       "16742        Singapore Sports Council (Sport Singapore)   \n",
       "\n",
       "                                     agency_clean  \n",
       "16411  Singapore Sports Council (Sport Singapore)  \n",
       "16742  Singapore Sports Council (Sport Singapore)  "
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Replace rows with Singapore Sports Council as agency name with new brand name Sport Singapore for standardization \n",
    "\n",
    "# Find unique rows related to Sports\n",
    "# df[df['agency_clean'].str.contains(\"Sports\", case=False, na=False)][['agency_raw', 'agency_clean']].drop_duplicates()\n",
    "\n",
    "# Show rows with old name\n",
    "df[df['agency_clean'].str.contains(\"Singapore Sports Council\", case=False, na=False)][['agency_raw', 'agency_clean']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "93d0af88-9eaf-4de1-92c5-efaafb602770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Singapore Sports Council with Sport Singapore - new name since 2014\n",
    "df['agency_clean'] = df['agency_raw'].replace(\n",
    "    {r'^Singapore Sports Council.*$': 'Sport Singapore'},\n",
    "    regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "9b42ba00-e7b6-41fd-b75a-b094b2416847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be empty\n",
    "# df[df['agency_clean'].str.contains(\"Singapore Sports Council\", case=False, na=False)][['agency_raw', 'agency_clean']].drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "0ffbcbd5-db1c-41b5-a225-ffd9cb1d6dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_raw</th>\n",
       "      <th>agency_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16411</th>\n",
       "      <td>Singapore Sports Council (Sport Singapore) - SPC</td>\n",
       "      <td>Sport Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16742</th>\n",
       "      <td>Singapore Sports Council (Sport Singapore)</td>\n",
       "      <td>Sport Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             agency_raw     agency_clean\n",
       "16411  Singapore Sports Council (Sport Singapore) - SPC  Sport Singapore\n",
       "16742        Singapore Sports Council (Sport Singapore)  Sport Singapore"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new value updated\n",
    "df[df['agency_clean'].str.contains(\"Sport Singapore\", case=False, na=False)][['agency_raw', 'agency_clean']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "e4d397c6-067c-4900-8a86-a5059f8ae9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "df['agency_parent'] = df['agency_clean']\n",
    "df['agency_child'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "aac08c24-319e-44cb-a9e0-5cb510d8051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[df['agency_clean'].str.contains(r'[^ ]-[^ ]', regex=True)][['agency_clean']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "09bf3bcc-f6d1-44b3-80e8-b9d8e386e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Default values\n",
    "df['agency_parent'] = df['agency_clean']\n",
    "df['agency_child'] = None\n",
    "\n",
    "# Outlier partial match patterns (do not split these even if they contain dash)\n",
    "outlier_patterns = [\n",
    "    \"ISEAS - Yusof Ishak Institute\",\n",
    "    \"Info - communications Media Development Authority\",\n",
    "    \"Anglo - Chinese School\"\n",
    "]\n",
    "\n",
    "# Escape dashes to safely compile regex\n",
    "outlier_regex = \"|\".join([re.escape(p) for p in outlier_patterns])\n",
    "\n",
    "# Default assignments\n",
    "df['agency_parent'] = df['agency_clean']\n",
    "df['agency_child'] = None\n",
    "\n",
    "# Split on dash unless it matches an exception pattern\n",
    "split_mask = (\n",
    "    df['agency_clean'].str.contains(r'\\s*-\\s*', regex=True, na=False) &\n",
    "    ~df['agency_clean'].str.contains(outlier_regex, case=False, na=False)\n",
    ")\n",
    "split_df = df.loc[split_mask, 'agency_clean'].str.split(r'\\s*-\\s*', n=1, expand=True, regex=True)\n",
    "\n",
    "df.loc[split_mask, 'agency_parent'] = split_df[0]\n",
    "df.loc[split_mask, 'agency_child'] = split_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "b8479771-d568-469f-beae-037307e6f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compact hyphens remaining: 0\n",
      "                                                    agency_clean           agency_parent                           agency_child\n",
      "Prime Minister's Office - Corrupt Practices Investigation Bureau Prime Minister's Office Corrupt Practices Investigation Bureau\n",
      "                  Prime Minister's Office - Elections Department Prime Minister's Office                   Elections Department\n",
      "                  Prime Minister's Office - Ministry Headquarter Prime Minister's Office                   Ministry Headquarter\n",
      "                                     agency_clean                                     agency_parent agency_child\n",
      "Info - communications Media Development Authority Info - communications Media Development Authority         None\n",
      "             Anglo - Chinese School (Independent)              Anglo - Chinese School (Independent)         None\n",
      "                    ISEAS - Yusof Ishak Institute                     ISEAS - Yusof Ishak Institute         None\n"
     ]
    }
   ],
   "source": [
    "# 1) No more compact dashes like A-B\n",
    "print(\"Compact hyphens remaining:\",\n",
    "      df['agency_clean'].str.contains(r'[^ ]-[^ ]', regex=True, na=False).sum())\n",
    "\n",
    "# 2) Examples that should now split\n",
    "print(\n",
    "    df[df['agency_clean'].str.contains(r\"Prime Minister's Office - \", na=False)]\n",
    "      [['agency_clean','agency_parent','agency_child']]\n",
    "      .drop_duplicates()\n",
    "      .head(3).to_string(index=False)\n",
    ")\n",
    "\n",
    "# 3) Outliers are not split\n",
    "print(\n",
    "    df[df['agency_clean'].str.contains(outlier_regex, case=False, na=False)]\n",
    "      [['agency_clean','agency_parent','agency_child']]\n",
    "      .drop_duplicates()\n",
    "      .head(5).to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "584fa30d-de70-4f86-9268-2fce4728454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Rows where dash might not have been split (still compact):\n",
      "Empty DataFrame\n",
      "Columns: [agency_clean, agency_parent, agency_child]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Rows with unsplit dash\n",
    "unsplit_dash = df[\n",
    "    df['agency_clean'].str.contains(r'[^ ]-[^ ]', regex=True) &\n",
    "    (df['agency_child'].isna())\n",
    "]\n",
    "\n",
    "print(\"❌ Rows where dash might not have been split (still compact):\")\n",
    "print(\n",
    "    unsplit_dash[['agency_clean', 'agency_parent', 'agency_child']]\n",
    "    .drop_duplicates()\n",
    "    .to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "d8b27bd2-eea2-480f-b2a2-f68b52ecb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers that should not be split:\n",
      "                                     agency_clean                                     agency_parent agency_child\n",
      "Info - communications Media Development Authority Info - communications Media Development Authority         None\n",
      "                    ISEAS - Yusof Ishak Institute                     ISEAS - Yusof Ishak Institute         None\n"
     ]
    }
   ],
   "source": [
    "# Check outliers were not split\n",
    "print(\"Outliers that should not be split:\")\n",
    "print(\n",
    "    df[df['agency_clean'].isin(outlier_patterns)]\n",
    "      [['agency_clean', 'agency_parent', 'agency_child']]\n",
    "      .drop_duplicates()\n",
    "      .to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "2b05d663-0595-4ed4-9dc7-90a33862cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique agencies before cleaning: 111\n",
      "Unique agencies after cleaning: 109\n"
     ]
    }
   ],
   "source": [
    "# Inspecting differences\n",
    "agency_check = df[['agency_raw','agency_clean','agency_parent','agency_child']].drop_duplicates()\n",
    "\n",
    "print(\"\\nUnique agencies before cleaning:\", df['agency_raw'].nunique())\n",
    "print(\"Unique agencies after cleaning:\", df['agency_clean'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "e5ec0470-f29e-41cd-ab28-2816e9bb9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check - Show examples of rows that actually changed\n",
    "changed = agency_check[agency_check['agency_raw'] != agency_check['agency_clean']]\n",
    "# print(\"\\nExamples of changed agencies:\")\n",
    "# print(changed.sample(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "1fb4a394-90d3-4c3e-81dd-116705aeb633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported agency_raw vs agency_clean to agency_clean_check.csv\n"
     ]
    }
   ],
   "source": [
    "# ========= EXTENDED CHECK (for debugging, comment code below when not needed) ==============\n",
    "# Purpose: Exporting agency-related columns with diagnostic flags to an excel sheet for manual review \n",
    "\n",
    "# Add \"changed\" flag (so you can sort easily)\n",
    "agency_check['changed'] = agency_check['agency_raw'] != agency_check['agency_clean']\n",
    "\n",
    "# Sort by changed first (changed=True rows appear at the top)\n",
    "agency_check = agency_check.sort_values(by=\"changed\", ascending=False)\n",
    "\n",
    "# Adding diagnostics flags that help you see what was fixed\n",
    "agency_check['had_double_spaces'] = agency_check['agency_raw'].str.contains(r\"\\s{2,}\", regex=True)\n",
    "agency_check['had_dash'] = agency_check['agency_raw'].str.contains(r'[^ ]-[^ ]', regex=True)\n",
    "agency_check['was_exception'] = agency_check['agency_clean'].str.contains(outlier_regex, case=False, regex=True) #outlier names\n",
    "agency_check['was_split'] = (\n",
    "    agency_check['agency_child'].notna() &\n",
    "    ~agency_check['was_exception']\n",
    ")\n",
    "# Exporting agency-related columns to a CSV for manual review\n",
    "agency_check.to_csv(\"agency_clean_check.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Exported agency_raw vs agency_clean to agency_clean_check.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045aff0-5c33-4ec4-a780-c4d751ebbfe8",
   "metadata": {},
   "source": [
    "## 4) award_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034854aa-719d-4736-94e2-3d4c004ef7d3",
   "metadata": {},
   "source": [
    "- Currently, `award_date` is in `dd/mm/yyyy` or `d/m/yyyy` formats\n",
    "- Transformation(s):\n",
    "    - Convert to `datetime`.\n",
    "        - There’s no separate `date` dtype that works nicely with vectorized operations.\n",
    "        - Even if your data only has dates (no times), Pandas stores it as datetime because its `datetime64` is the standard for date-like data.\n",
    "        - You could technically convert to Python’s datetime.date, but then your column becomes object dtype (slower, clunkier, not recommended).\n",
    "        - Any invalid/missing dates will become `NaT`\n",
    "- Note: In SQLAlchemy load step, map it to `DATE`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7fa70-1559-4e29-a359-715f5a14a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dayfirst = True because dates are in dd/mm/yyyy format. with errors='coerce', if pandas sees an invalid date, it will set it as NaT (Not a Time) \n",
    "df['award_date'] = pd.to_datetime(df['award_date'], dayfirst=True, errors='coerce')\n",
    "# confirming that it's now datetime64, not object (string)\n",
    "print(\"Award date dtype:\", df['award_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86619b36-604d-49bd-9d93-1a728da3c271",
   "metadata": {},
   "source": [
    "## 5) `tender_detail_status`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccceec-6eee-4b94-a497-f7bb9cd51433",
   "metadata": {},
   "source": [
    "**Has 4 different statuses:**\n",
    "- `Awarded to Suppliers` - Supplier was chosen and amount is recorded.\n",
    "- `Awarded by Items` - Instead of one supplier getting the whole thing, individual line items were awarded to different suppliers. \n",
    "- `Awarded to No Suppliers` - Tender closed but nobody was awarded. Hence corresponding column `awarded_amt = 0`\n",
    "- `Award by Interface` - System generated status. Usually means the award details were inserted by an automated interface instead of manual entry. Functionally, it's still an award.\n",
    "\n",
    "**Status phrasing is inconsistent.**\n",
    "- `Awarded by items` vs `Awarded to Suppliers` mix `\"by\"` vs `\"to\"`\n",
    "- `Award by interface record` does not follow the same tense/grammar pattern like the other statuses.\n",
    "- if we want to run `SELECT COUNT(*) WHERE tender_detail_status LIKE `Awarded%`, we will miss `Award by interface record`. The subtle difference makes grouping harder.\n",
    "\n",
    "- Ideally we want **categorical columns** to be standardized into a controlled vocabulary (e.g. enum or lookup table) Why?\n",
    "    - Consistency across rows\n",
    "    - Easier to group/aggregate in SQL\n",
    "    - Makes schema design more meaningful (e.g. a dimension table for tender status could have 4 values).\n",
    "\n",
    "\n",
    "- **Transformation(s):**\n",
    "    - Step 1 - Trim whitespace\n",
    "    - Step 2 - Map to a controlled vocabulary for easier querying in DB (e.g. `\"AWARDED_ITEMS\"`, `\"AWARDED_SUPPLIERS\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c2c2b-2cf8-422f-a170-4d4bdc8d5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tender_detail_status'] = df['tender_detail_status'].str.strip() #strip whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9775a-9b09-48c8-8341-48c4b021299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to raw text into clean categories\n",
    "status_map = {\n",
    "    \"Award by interface record\": \"AWARDED_INTERFACE\",\n",
    "    \"Awarded by Items\": \"AWARDED_ITEMS\",\n",
    "    \"Awarded to No Suppliers\": \"NO_SUPPLIERS\",\n",
    "    \"Awarded to Suppliers\": \"AWARDED_SUPPLIERS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9d52e-5a5b-4739-84ce-b27cad2f36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the clean values\n",
    "df['tender_detail_status_clean'] = df['tender_detail_status'].map(status_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f43ef-9595-412e-b489-c76bf12c3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of statuses after cleaning\n",
    "print(\"Tender detail status counts:\\n\", df['tender_detail_status_clean'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935f7c2-96c4-45ca-9a16-77f86800afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Tender status consistency check. \n",
    "unexpected_status = df.loc[~df['tender_detail_status'].isin(status_map.keys())]\n",
    "# empty dataframe as dataset only has 4 statuses we already mapped. \n",
    "# While there are no surprise values in this dataset, it's just a safeguard for future updates.\n",
    "# E.g. imagine a new status \"Cancelled\" appears. this check will flag it\n",
    "print(unexpected_status) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268af6a8-e39d-4473-b32a-f1c5995039e1",
   "metadata": {},
   "source": [
    "## 6) `supplier_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e50853-ee6a-4b77-b38e-a47e70d720fc",
   "metadata": {},
   "source": [
    "- Supplier names are inconsistent. Messy casing & suffixes due to different capitalization style.\n",
    "    - E.g. `KPMG SERVICES PTE. LTD`, `CRIMSONLOGIC PTE LTD`, `Checkbox Technology Pte Ltd`\n",
    "- If we don’t standardize, queries like \"GROUP BY supplier\" will count them separately.\n",
    "- Important as we want to avoid duplicates in SQL when grouping by supplier\n",
    "\n",
    "- **Transformations:**\n",
    "    - Strip whitespace\n",
    "    - Identify rows with double spaces. Why?\n",
    "        - If you do a `GROUP BY supplier_name` in SQL, `BGPROTECT  LTD` and `BGPROTECT LTD` will be treated as two different suppliers.\n",
    "    - Normalize suffixes (e.g. `PTE LTD, PTE. LTD -> PTE LTD)\n",
    "    - Remove trailing periods\n",
    "    - When there are no supplier for a given tender, set supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "14722c01-be67-40ae-ba29-1cb52608eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Remove leading/trailing spaces make everything uppercase for consistency\n",
    "df['supplier_name'] = df['supplier_name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "629b818a-6c95-49f8-b607-e778fa1dd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with double spaces: 6\n"
     ]
    }
   ],
   "source": [
    "# 2) Collapse double/triple spaces \n",
    "\n",
    "# Identify rows with double spaces in supplier_name column values\n",
    "mask = df['supplier_name'].str.contains(r'\\s{2,}', na=False) #2 or more double spaces, na=False ignore NaN values if any\n",
    "df[mask].head(10)\n",
    "print(\"Rows with double spaces:\", mask.sum()) #if 0, means it's clean. otherwise, it means we have supplier names with double spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6fc89a11-d602-4fef-9288-4b95b26ce7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BGPROTECT  LTD',\n",
       "       'TAISEI CORPORATION-CHINA STATE CONSTRUCTION  ENGINEERING CORPORATION LIMITED SINGAPORE BRANCH JOINT VENTURE',\n",
       "       'SUEZ (SINGAPORE) SERVICES  PTE. LTD.', 'KASTURI  PRODUCTION',\n",
       "       'CHEMICALS TESTING & CALIBRATION  LABORATORY',\n",
       "       'WINNIE MANIKAM  KRISHNAVENI MRS WINNIE UBBINK'], dtype=object)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show distinct supplier names that have double spaces \n",
    "df.loc[mask, 'supplier_name'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "19a1acc5-d8db-4557-907c-cba81c7ea0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with double spaces: 6\n"
     ]
    }
   ],
   "source": [
    "# ensure supplier names are normalized. so no duplicates due to space issues\n",
    "df['supplier_name'] = df['supplier_name'].str.replace(r'\\s+', ' ', regex=True) \n",
    "print(\"Rows with double spaces:\", mask.sum()) #if 0, means it's clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "8b9eb855-f118-46a5-b7ac-f68f5cc73582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Standardize PTE LTD variants. \n",
    "# Note: Not ideal to strip PTE LTD as we would risk collisions. E.g. ABC PTE LTD (company) vs ABC LLP (partnership) run by diff owners\n",
    "\n",
    "# Normalizing common suffixes using regex (pattern matching)\n",
    "df['supplier_name'] = df['supplier_name'].str.replace(r'PTE\\.?', 'PTE', regex=True)\n",
    "df['supplier_name'] = df['supplier_name'].str.replace(r'LTD\\.?', 'LTD', regex=True)\n",
    "\n",
    "# Handling rare 'PTE LIMITED' \n",
    "df['supplier_name'] = df['supplier_name'].str.replace(r'PTE LIMITED', 'PTE LTD', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "ea0c8262-cf86-4ed8-9608-a50411304d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing periods. Some suppliers end with a dot\n",
    "df['supplier_name'] = df['supplier_name'].str.replace(r'\\.\\s*$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "91722960-80c1-42b6-a9c4-ac8136e30eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add upper  case for consistency in SQL group buys\n",
    "df['supplier_name'] = df['supplier_name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "6fb2a06c-2693-4967-bb1f-329add3a788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If award_amt = 0, supplier_name = \"Unknown\", set supplier_name to NULL in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "e6663e8a-7ce1-48cb-89c3-8af7a91543d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample suppliers:\n",
      " 8508                         ELITE LINGUISTIC ACADEMY LLP\n",
      "16540                    YAMAZAKI MAZAK SINGAPORE PTE LTD\n",
      "15459                                  GM APPAREL PTE LTD\n",
      "451                              FLEISHMANHILLARD PTE LTD\n",
      "1193                                 THE PESTMAN, PTE LTD\n",
      "7021                                    GYMSPORTZ PTE LTD\n",
      "5472     ABBOTT LABORATORIES (SINGAPORE ) PRIVATE LIMITED\n",
      "8754                                    E3 DESIGN PTE LTD\n",
      "5684         HITACHI SYSTEMS NETWORK TECHNOLOGIES PTE LTD\n",
      "16516                             EXILE SOLUTIONS PTE LTD\n",
      "Name: supplier_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample suppliers:\\n\", df['supplier_name'].drop_duplicates().sample(10)) #to check if cleaning works as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed942199-127c-42bb-a95c-4383333851cf",
   "metadata": {},
   "source": [
    "## 7) `awarded_amt` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dd5c33-1ded-4ba4-8295-0e8de626b31d",
   "metadata": {},
   "source": [
    "- No currency symbol cleanup is needed\n",
    "- Ensure the award amount is numeric.\n",
    "- If tender was closed with no suppliers, this column should be 0.\n",
    "- **Transformation(s):**\n",
    "    - Convert to numeric explicitly\n",
    "    - Enforce rule: if status == `No Suppliers`, check awarded_amt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18ce37-3dab-4f97-8fed-e725cf5a14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric, force errors to NaN (null).\n",
    "df['awarded_amt'] = pd.to_numeric(df['awarded_amt'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca83ab-0f5a-41a5-9061-273424d8afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business rule check - \"No Suppliers\" tenders should ALWAYS HAVE awarded_amt = 0\n",
    "mask_no_suppliers = df['tender_detail_status_clean'] == \"NO_SUPPLIERS\"\n",
    "if not (df.loc[mask_no_suppliers, 'awarded_amt'] == 0).all():\n",
    "    print(\"WARNING: Some NO_SUPPLIERS tenders have non-zero awarded_amt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a63a74-73ca-4f87-ade9-6ac2d6bec845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using describe() to give us min, max, mean, percentiles. Good for spotting outliers.\n",
    "print(\"Awarded_amt stats:\\n\", df['awarded_amt'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadd157-4de8-40db-b0c8-78ea8e215a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For outlier sanity check experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5c289-7dc9-48ec-a176-b9d6f8f0bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) look for abnormal spikes by percentiles\n",
    "df['awarded_amt'].describe(percentiles=[.5, .9, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0756b-b64f-4edc-9f41-c29a1345ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Check for negative amounts\n",
    "print(\"Negative amounts:\", df[df['awarded_amt'] < 0]) #should be empty anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b5088-9fbb-4416-b4b1-41837ee94fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Check for suspiciously large/extreme amounts (e.g. > 1 billion SGD)\n",
    "high_values = df[df['awarded_amt'] > 1e9]\n",
    "print(\"Suspiciously large amounts:\", high_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "12a0617b-0aec-4624-821e-ed8d5d709828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values after cleaning:\n",
      " vault_id                        0\n",
      "tender_no                       0\n",
      "tender_description              0\n",
      "agency                          0\n",
      "award_date                      0\n",
      "tender_detail_status            0\n",
      "supplier_name                   0\n",
      "awarded_amt                     0\n",
      "tender_no_clean                 0\n",
      "tender_description_clean        0\n",
      "agency_raw                      0\n",
      "agency_clean                    0\n",
      "agency_parent                   0\n",
      "agency_child                15294\n",
      "supplier_name_clean             0\n",
      "is_awarded                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for Nan/Nulls explicitly. Why? After .to_datetime() and .to_numeric(), some rows may have become NaT or NaN.\n",
    "print(\"Checking for null values after cleaning:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caefab7-241a-4dfb-85d2-6f4242a4992e",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831b1ed-6337-4661-8220-352129e33df3",
   "metadata": {},
   "source": [
    "- Primary Key\n",
    "    - Since `tender_no` is not unique, we can either have a composite key (e.g. tender_no, supplier_name) or surrogate key `id` before loading. Surrogate key seems more futureproof.\n",
    "    - E.g. Of making a surrogate key - `id BIGSERIAL PRIMARY KEY`\n",
    "\n",
    "- Use PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b9f7a-78ab-47e4-b2f3-d05688999271",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "9d80f15b-7cc5-4759-bd80-1d4d8dfa8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "agency_map = {\n",
    "    # Ministries\n",
    "    \"Ministry Of Defence\": \"MINDEF\",\n",
    "    \"Ministry Of Education\": \"MOE\",\n",
    "    \"Ministry Of Finance\": \"MOF\",\n",
    "    \"Ministry Of Foreign Affairs\": \"MFA\",\n",
    "    \"Ministry Of Health\": \"MOH\",\n",
    "    \"Ministry Of Home Affairs\": \"MHA\",\n",
    "    \"Ministry Of Manpower\": \"MOM\",\n",
    "    \"Ministry Of National Development\": \"MND\",\n",
    "    \"Ministry Of Social And Family Development\": \"MSF\",\n",
    "    \"Ministry Of Sustainability And The Environment\": \"MSE\",\n",
    "    \"Ministry Of Trade & Industry\": \"MTI\",\n",
    "    \"Ministry Of Transport\": \"MOT\",\n",
    "    \"Ministry Of Communications And Information\": \"MCI\",\n",
    "\n",
    "    # Statutory board\n",
    "    \"Accounting And Corporate Regulatory Authority\": \"ACRA\",\n",
    "    \"Building And Construction Authority\": \"BCA\",\n",
    "    \"Board Of Architects\": \"BOA\",\n",
    "    \"Civil Aviation Authority Of Singapore\": \"CAAS\",\n",
    "    \"Competition And Consumer Commission Of Singapore (Cccs)\": \"CCCS\",\n",
    "    \"Council For Estate Agencies\": \"CEA\",\n",
    "    \"Defence Science And Technology Agency\": \"DSTA\",\n",
    "    \"Economic Development Board\": \"EDB\",\n",
    "    \"Energy Market Authority Of Singapore\": \"EMA\",\n",
    "    \"Enterprise Singapore\": \"ESG\",\n",
    "    \"Gambling Regulatory Authority Of Singapore (Gra)\": \"GRA\",\n",
    "    \"Health Promotion Board\": \"HPB\",\n",
    "    \"Health Sciences Authority\": \"HSA\",\n",
    "    \"Home Team Science And Technology Agency\": \"HTX\",\n",
    "    \"Housing And Development Board\": \"HDB\",\n",
    "    \"Infocomm Media Development Authority\": \"IMDA\",\n",
    "    \"Inland Revenue Authority Of Singapore\": \"IRAS\",\n",
    "    \"Intellectual Property Office Of Singapore\": \"IPOS\",\n",
    "    \"Jurong Town Corporation\": \"JTC\",\n",
    "    \"Land Transport Authority\": \"LTA\",\n",
    "    \"Majlis Ugama Islam Singapura\": \"MUIS\",\n",
    "    \"Maritime And Port Authority Of Singapore\": \"MPA\",\n",
    "    \"National Environment Agency\": \"NEA\",\n",
    "    \"National Heritage Board\": \"NHB\",\n",
    "    \"National Library Board\": \"NLB\",\n",
    "    \"National Parks Board\": \"NPARKS\",\n",
    "    \"People'S Association\": \"PA\",\n",
    "    \"Professional Engineers Board\": \"PEB\",\n",
    "    \"Public Utilities Board\": \"PUB\",\n",
    "    \"Public Transport Council\": \"PTC\",\n",
    "    \"Sentosa Development Corporation\": \"SDC\",\n",
    "    \"Singapore Civil Defence Force\": \"SCDF\",\n",
    "    \"Singapore Examinations And Assessment Board\": \"SEAB\",\n",
    "    \"Singapore Food Agency\": \"SFA\",\n",
    "    \"Singapore Land Authority\": \"SLA\",\n",
    "    \"Singapore Labour Foundation\": \"SLF\",\n",
    "    \"Singapore Medical Council\": \"SMC\",\n",
    "    \"Singapore Nursing Board\": \"SNB\",\n",
    "    \"Singapore Police Force\": \"SPF\",\n",
    "    \"Singapore Prison Service\": \"SPS\",\n",
    "    \"Singapore Tourism Board\": \"STB\",\n",
    "    \"Skillsfuture Singapore\": \"SSG\",\n",
    "    \"Urban Redevelopment Authority\": \"URA\",\n",
    "    \"Workforce Singapore\": \"WSG\",\n",
    "    \"Yellow Ribbon Singapore\": \"YRSG\",\n",
    "    \"Civil Service College\": \"CSC\",\n",
    "    \"Iseas - Yusof Ishak Institute\": \"ISEAS\",\n",
    "\n",
    "    #Councils\n",
    "    \"National Arts Council\": \"NAC\",\n",
    "    \"National Council Of Social Service\": \"NCSS\",\n",
    "    \"National Youth Council\": \"NYC\",\n",
    "\n",
    "    #IHLs\n",
    "    \"Institute Of Technical Education\": \"ITE\",\n",
    "    \"Temasek Polytechnic\": \"TP\",\n",
    "    \"Nanyang Polytechnic\": \"NYP\",\n",
    "    \"Ngee Ann Polytechnic\": \"NP\",\n",
    "    \"Republic Polytechnic\": \"RP\",\n",
    "    \"Singapore Polytechnic\": \"SP\",\n",
    "    \"National University Of Singapore\": \"NUS\",\n",
    "    \"Nanyang Technological University\": \"NTU\",\n",
    "    \"Singapore Management University\": \"SMU\",\n",
    "    \"Singapore Institute Of Technology\": \"SIT\",\n",
    "    \"Singapore University Of Technology And Design\": \"SUTD\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
